---
layout:     post
title:      深度神经网络的推理时间压缩和加速   
subtitle:   
date:       2018-4-2
author:     WMX
header-img: img/tech-eye.jpg
catalog: true
tags:
    - 计算机视觉
    - 深度学习
    - 深度神经网路
    - 推理时间压缩和加速
---

# 前言
GitHub原文 [点这里 ->> ](https://github.com/wmx17806275903/wmx17806275903.github.io/)
如果对您有帮助，请给我小星星（Star一下呗）。

## 推理时间压缩和加速方法

相关工作通常分为四类。

1.张量分解方法[11,12]将卷积层分解成几个较小的卷积层，这降低了总体复杂度和参数数量。这类方法通常涉及低阶估计过程和微调过程，导致缓慢的训练程序。

2.参数量化方法[13,14]建议在神经网络中使用低精度参数，并提供显着的理论加速和巨大的内存节省。然而，目前的硬件并未针对低精度计算进行优化，因此量化方法
需要特定的硬件才能实现理想的加速。

3.网络修剪（剪枝）方法[15,16]试图发现和缓解深度神经网络中的参数和结构冗余。早期的修剪方法采用非结构化修剪方案，并引发随机存储器访问，目前的硬件并不能
很好地支持这种访问。最近关于网络修剪的研究主要集中在结构修剪以利用现有硬件。

4.最后，紧凑型网络[17,18,19]专门设计用在移动或嵌入式设备上使用精确和计算经济的网络。与其他主要侧重于压缩预训练模型的方法不同，紧凑型网络可以从头开始
训练。此外，紧凑型网络与其他方法正交还可以进一步加速。鉴于这些优点，已经提出了各种紧凑型网络架构。在这些网络中，MobileNet和ShuffleNet性能最好。

先po这么些
